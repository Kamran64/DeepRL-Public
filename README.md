# README

In this folder, you will find the three implementations detailed in the report. These are:
- Cartpole with Deep Q-Learning
- Bipedal Walker with PPO

The source IPYNB's alongside the HTML formatted versions of the code are included.

## Cartpole with Deep Q-Learning

A solution to OpenAI Gym's Cartpole environment using Deep Q-Learning. The code includes an agent for each configuration outlined in the report.

Prerequisites:
- Gym: https://gym.openai.com/docs/#installation
- PyTorch (Tested with 1.7.0): https://pytorch.org/
- NumPy (Tested with 1.19.5): https://numpy.org/install/
- Matplotlib (Tested with 3.2.2):https://matplotlib.org/stable/users/installing.html
- JupyterLab: https://jupyter.org/install
- Built in modules: Math, Random

Execution:
- Open Cartpole_DQN-TriAgent.ipynb in Jupyter Labs
- Run -> Run All

The code has only been tested using macOS Catalina.

## Bipedal Walker with PPO

A solution to OpenAI Gym's Bipedal Walker environment using PPO with Actor Critic. The code includes an agent for each configuration outlined in the report.

Prerequisites:
- Gym: https://gym.openai.com/docs/#installation
- Box2D: https://pypi.org/project/Box2D/
- PyTorch (Tested with 1.7.0): https://pytorch.org/
- NumPy (Tested with 1.19.5): https://numpy.org/install/
- Matplotlib (Tested with 3.2.2): https://matplotlib.org/stable/users/installing.html
- JupyterLab: https://jupyter.org/install
- Built in modules: Math, Random

Execution:
- Open BipedalWalker-DuoAgent.ipynb in Jupyter Labs
- Run -> Run All

The code has only been tested using macOS Catalina.
